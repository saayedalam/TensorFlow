{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saayed Alam <br> DATA 622 Final Project <br> Machine Learning and Big Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "For this project, I will build an image recognition model using Convolutional Neural Networks (CNN), Tensorflow and Keras. \n",
    "\n",
    "- **Why Convolutional Neural Networks?** <br> A Convolutional Neural Network is a Deep Learning algorithm which can take in an input image, assign importance to various aspects in the image and be able to differentiate one from the other. The pre-processing required in a CNN is much lower as compared to other classification algorithms. \n",
    "\n",
    "- **Why TensorFlow and Keras?** <br> TensorFlow is an open-source library for building Machine learning models at large scale. It is by far the most popular library for building deep learning models. It also has the strongest and a huge community of developers, researchers, and contributors. Keras is a high-level neural networks API, written in Python and capable of running on top of Tensorflow. It is very popular in the research and development community because it supports rapid experimentation, prototyping, and user-friendly API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "As assigned by the Professor, I will use the MNIST dataset. The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. You can learn more about the dataset [here](http://yann.lecun.com/exdb/mnist/). If you scroll down, you will notice all the algorithms and their respective accuracy scores tested on this dataset. I will use it as reference when I fit the model. \n",
    "\n",
    "TensorFlow(TF) allows to download the MNIST dataset through their API. \n",
    "- `x_train` has 60,000 images\n",
    "- `x_test` has 10,000 images\n",
    "- `y_train` and `y_test` have labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I transform the dataset for the model, let us explore an image. Since there are 60,000 images, I will pick a random number from the bracket and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce43c95a88>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a digit between 1 to 60,000\n",
    "image_index = 12345\n",
    "print(y_train[image_index])\n",
    "\n",
    "# visualize the image\n",
    "%matplotlib inline\n",
    "plt.imshow(x_train[image_index], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I reshape and normalize the dataset in order to extract features from the source image. It is a necessary step to use the dataset in Keras API. \n",
    "\n",
    "- Reshape: Keras API requires 4-dims numpy arrays. We can see below, our dataset is 3-dims i.e. 60,000 images and 28 x 28 pixel per image in size. \n",
    "- Normalize: A neural network models always require normalized data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# shape of the raw dataset\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# reshaping the dataset\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# convert to get decimal points and normalize the data by dividing it to the max value i.e. 255 \n",
    "x_train = x_train.astype('float32') / 255 \n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# verifying the transformation\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "Finally I build a Convolutional Neural Networks using Keras API.\n",
    "***\n",
    "- `Sequential` allows us to create model layer-by-layer. I can create a Sequential model by passing a list of layer instances to the constructor.\n",
    "***\n",
    "- `Conv2D` the objective of this layer is to extract the high-level features such as edges, from the input image.  \n",
    "    1. the dimensionality of the output space of this layer,\n",
    "    2. the height and width of the convolution layer,\n",
    "    3. the model needs to know what input shape it should expect. \n",
    "***\n",
    "- `MaxPooling2D` the Pooling layer is responsible for reducing the spatial size of the previous layer. \n",
    "    1. factors by which to downscale.  \n",
    "***    \n",
    "- `Flatten` removes all of the dimensions except for one.\n",
    "***\n",
    "- `Dense` a dense layer is just a regular layer of neurons in a neural network. Each neuron recieves input from all the neurons in the previous layer, thus densely connected. \n",
    "    1. the activation function is responsible for transforming the summed weighted input from the node into the activation of the node or output for that input,\n",
    "    2. relu or rectified linear activation function is a piecewise linear function that will output the input directly if is positive, otherwise, it will output zero. It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.\n",
    "***\n",
    "- `Dropout` it is a technique used to tackle Overfitting. The Dropout method in Keras takes in a float between 0 and 1, which is the fraction of the neurons to drop. \n",
    "***\n",
    "- `Dense` the final Dense layer must have 10 neurons since I have 10 number classes.\n",
    "    1. softmax function or normalized exponential function can be used to represent a categorical distribution i.e. a probability distribution over ‘K’ different possible outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Sequential([\n",
    "    Conv2D(28, kernel_size = (3, 3), input_shape = input_shape),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation = tf.nn.relu),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have created the model, we are ready to optimize and fit the model. Compile defines the loss function, the optimizer and the metrics. These are necessary to train a neural network. I will use the `sparse_categorical_crossentropy` for loss function and `adam` for the optimizer. With the help of the optimization function, loss function learns to reduce the error in prediction.\n",
    "- `sparse_categorical_crossentropy` this function is used when classes are mutually exclusive (e.g. when each sample belongs exactly to one class).\n",
    "- `adam` Adam is an adaptive learning rate optimization algorithm that’s been designed specifically for training deep neural networks. You can read more about it [here](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c). The algorithms leverages the power of adaptive learning rates methods to find individual learning rates for each parameter.\n",
    "- `accuracy` it is the fraction of predictions the model got right.\n",
    "- `epochs` it is a measure of the number of times all of the training dataset are used once to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 30s 495us/step - loss: 0.1742 - accuracy: 0.9482\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0657 - accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0436 - accuracy: 0.9866\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 30s 506us/step - loss: 0.0339 - accuracy: 0.9884\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0242 - accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 32s 526us/step - loss: 0.0221 - accuracy: 0.9923\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 31s 513us/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 31s 523us/step - loss: 0.0119 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ce464dd688>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# complile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(x = x_train, y = y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation & Prediction\n",
    "Lastly, I evaluate my model and achieve 98.6% accuracy with my model. I also make a prediction to verify the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 93us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06546762842676754, 0.9855999946594238]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPEUlEQVR4nO3df4xV9ZnH8c+jVH61EZDBEIqOVhJ/rEqbK6yyUddGFCTBxlRrohGjGWMklsQ/FjRaYmJCzFpczVpFxbKmi6lpjWOiu1XShKhJ9YoouLjiEhx+jDCIRhoTu9Bn/5jjZopzvme459wf8LxfyeTO3M+cOY+X+Xju3O+995i7C8Cx77h2DwCgNSg7EARlB4Kg7EAQlB0IYlQrdzZ58mTv7u5u5S6BULZv3659+/bZcFmpspvZlZL+RdLxkp5y9xWp7+/u7la9Xi+zSwAJtVotN2v4bryZHS/pXyXNk3S2pOvN7OxGfx6A5irzN/ssSR+7+zZ3/4uk5yQtrGYsAFUrU/ZpknYM+Xpndt3fMLMeM6ubWX1gYKDE7gCUUabswz0I8K3n3rr7KnevuXutq6urxO4AlFGm7DslTR/y9fcl7S43DoBmKVP2tyXNMLPTzOwEST+T1FvNWACq1vDSm7sfNLPFkv5Tg0tvq939g8omA1CpUuvs7v6ypJcrmgVAE/F0WSAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCaOkpmxHP0qVLc7O+vr7kts8991wyv+CCC5L5Aw88kJvNmTMnue3YsWOT+dGIIzsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBME6O5JeeumlZH7//fcn83fffTc3c/fktmaWzOv1ejK/4oorcrPbbrstue1jjz2WzI9GpcpuZtslHZB0SNJBd69VMRSA6lVxZP9Hd99Xwc8B0ET8zQ4EUbbsLukPZvaOmfUM9w1m1mNmdTOrDwwMlNwdgEaVLfscd/+RpHmS7jCziw//Bndf5e41d691dXWV3B2ARpUqu7vvzi73SnpB0qwqhgJQvYbLbmbjzex733wuaa6kzVUNBqBaZR6NP1nSC9la6ChJ/+7u/1HJVDgihw4dys2efPLJ5LZr1qxJ5hs3bkzm559/fjJPraVfdtllyW2//PLLZF60zp4yf/78hrc9WjVcdnffJin9Lw2gY7D0BgRB2YEgKDsQBGUHgqDsQBC8xPUo8MUXXyTzJUuW5GbPPvtsqX0vW7YsmS9fvjyZ7927NzebMGFCctvbb789mRctvY0bNy43mz17dnLbYxFHdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgnX2DnDw4MFkfs899yTzsmvpKVdddVUyHzUq/Ss0efLk3GzlypXJbXt7e5P5eeedl8zXrl2bmxWt8R+LOLIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCss3eAordMfvzxxxv+2UWnPT7rrLOS+YUXXpjMd+/encwXLFiQm3366afJbV988cVkXuTMM88stf2xhiM7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgTBOnsH+Oyzz5L56NGjk/lxx+X/P/v1119Pbjtz5sxkvn///mQ+a9asZN7f35+bFb0n/cUXX5zMcWQKj+xmttrM9prZ5iHXTTKzV81sa3Y5sbljAihrJHfjfy3pysOuWyppnbvPkLQu+xpAByssu7uvl3T4fbmFktZkn6+RdHXFcwGoWKMP0J3s7v2SlF1OyftGM+sxs7qZ1QcGBhrcHYCymv5ovLuvcveau9e6urqavTsAORot+x4zmypJ2WX+qToBdIRGy94r6abs85sklXstIoCmK1xnN7O1ki6VNNnMdkr6haQVkn5rZrdI6pP002YOeaybMWNGMp8zZ04yX79+fW5WtIa/a9euZH711enHXot+/p133pmbFZ1/HdUqLLu7X58T/bjiWQA0EU+XBYKg7EAQlB0IgrIDQVB2IAhe4noUePTRR5P53LlzG8pGwt2T+erVq5P5okWLSu0f1eHIDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBsM5+FDjppJOS+ZQpue8KVvgS1rKmT5/e1J+P6nBkB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgWGdvga+//jqZb9q0KZnffPPNyXzUqPx/xnvvvTe57TPPPJPM+/r6kvnll1+ezJ966qncrOhtqidNmpTMcWQ4sgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEFb0vuBVqtVqXq/XW7a/VhkYGEjmPT09yby3t7fU/m+88cbcrOh93Yv+/e+7775kvnbt2mT+ySef5GbTpk1LbvvEE08k83nz5iXziGq1mur1ug2XFR7ZzWy1me01s81DrltuZrvMbGP2Mb/KgQFUbyR3438t6cphrl/p7jOzj5erHQtA1QrL7u7rJe1vwSwAmqjMA3SLzez97G7+xLxvMrMeM6ubWb3ob1sAzdNo2X8l6QeSZkrql/RQ3je6+yp3r7l7raurq8HdASirobK7+x53P+Tuf5X0pKRZ1Y4FoGoNld3Mpg758ieSNud9L4DOULjObmZrJV0qabKkPZJ+kX09U5JL2i7pNnfvL9rZ0bzOvm3bttxs9uzZyW337y/3+OaYMWOS+ZYtW3KzU045pdS+ixT9tz344IO52fPPP5/cdseOHcn82muvTeZPP/10bjZ69Ojktker1Dp74ZtXuPv1w1ydfysC6Eg8XRYIgrIDQVB2IAjKDgRB2YEgeCvpEVq8eHFuVnZpbezYscn8lVdeSebNXl5LKXq75xUrVuRmEyfmPstaknT33Xcn86KX155xxhm52fLly5PbHos4sgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAELyVdGbr1q3J/JxzzsnNDh06lNy2aB1948aNyTy1Xnw027dvXzIv+l254YYbkvmBAwdys48++ii57amnnprMO1Wpt5IGcGyg7EAQlB0IgrIDQVB2IAjKDgRB2YEgeD17C5x77rnJ/FhdRy8ybty4ZP7hhx8m888//zyZX3PNNbnZ1KlTc7NjFUd2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCdfbMjBkzkvm0adNys76+vuS2u3fvTuZfffVVMi9aj26ngwcPJvP33nsvNyt6PXrRa86nT5+ezB9++OHc7IQTTkhueywqPLKb2XQz+6OZbTGzD8zs59n1k8zsVTPbml2m3/EfQFuN5G78QUl3uftZkv5e0h1mdrakpZLWufsMSeuyrwF0qMKyu3u/u2/IPj8gaYukaZIWSlqTfdsaSVc3a0gA5R3RA3Rm1i3ph5L+JOlkd++XBv+HIGlKzjY9ZlY3s/rAwEC5aQE0bMRlN7PvSvqdpCXu/uVIt3P3Ve5ec/daV1dXIzMCqMCIym5m39Fg0X/j7r/Prt5jZlOzfKqkvc0ZEUAVCpfezMwkPS1pi7v/ckjUK+kmSSuyyxebMmGHWLduXW526aWXJrfduXNnMt+wYUMyv+iii5L5ccc1/nSJoqWzoj+9rrvuumT+xhtv5GajRqV//RYtWpTMH3rooWQ+YcKEZB7NSNbZ50i6UdImM/vmDc7v1mDJf2tmt0jqk/TT5owIoAqFZXf31yUN+6bzkn5c7TgAmoWnywJBUHYgCMoOBEHZgSAoOxAEL3EdodNPPz03K3opZup0z5J0ySWXJPO5c+cm84kTG3/BYdHLc998881kPn78+GR+66235mbLli1Lbtvd3Z3McWQ4sgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEKyzV2DMmDHJ/LXXXkvmK1euTOapt2OWpBNPPDE3e+utt5LbLliwIJkvXLgwmd91113JvMxr7VEt/iWAICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjW2VvgtNNOS+aPPPJIiyZBZBzZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiCIwrKb2XQz+6OZbTGzD8zs59n1y81sl5ltzD7mN39cAI0ayZNqDkq6y903mNn3JL1jZq9m2Up3/+fmjQegKiM5P3u/pP7s8wNmtkXStGYPBqBaR/Q3u5l1S/qhpD9lVy02s/fNbLWZDXsOIjPrMbO6mdUHBgZKDQugcSMuu5l9V9LvJC1x9y8l/UrSDyTN1OCR/6HhtnP3Ve5ec/daV1dXBSMDaMSIym5m39Fg0X/j7r+XJHff4+6H3P2vkp6UNKt5YwIoaySPxpukpyVtcfdfDrl+6pBv+4mkzdWPB6AqI3k0fo6kGyVtMrON2XV3S7rezGZKcknbJd3WlAkBVGIkj8a/LsmGiV6ufhwAzcIz6IAgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0GYu7duZ2YDkj4ZctVkSftaNsCR6dTZOnUuidkaVeVsp7r7sO//1tKyf2vnZnV3r7VtgIROna1T55KYrVGtmo278UAQlB0Iot1lX9Xm/ad06mydOpfEbI1qyWxt/ZsdQOu0+8gOoEUoOxBEW8puZlea2X+b2cdmtrQdM+Qxs+1mtik7DXW9zbOsNrO9ZrZ5yHWTzOxVM9uaXQ57jr02zdYRp/FOnGa8rbddu09/3vK/2c3seEkfSbpc0k5Jb0u63t3/q6WD5DCz7ZJq7t72J2CY2cWS/izp39z977LrHpS0391XZP+jnOju/9Qhsy2X9Od2n8Y7O1vR1KGnGZd0taRFauNtl5jrWrXgdmvHkX2WpI/dfZu7/0XSc5IWtmGOjufu6yXtP+zqhZLWZJ+v0eAvS8vlzNYR3L3f3Tdknx+Q9M1pxtt62yXmaol2lH2apB1Dvt6pzjrfu0v6g5m9Y2Y97R5mGCe7e780+MsjaUqb5zlc4Wm8W+mw04x3zG3XyOnPy2pH2Yc7lVQnrf/NcfcfSZon6Y7s7ipGZkSn8W6VYU4z3hEaPf15We0o+05J04d8/X1Ju9swx7DcfXd2uVfSC+q8U1Hv+eYMutnl3jbP8/866TTew51mXB1w27Xz9OftKPvbkmaY2WlmdoKkn0nqbcMc32Jm47MHTmRm4yXNVeedirpX0k3Z5zdJerGNs/yNTjmNd95pxtXm267tpz9395Z/SJqvwUfk/0fSPe2YIWeu0yW9l3180O7ZJK3V4N26/9XgPaJbJJ0kaZ2krdnlpA6a7VlJmyS9r8FiTW3TbP+gwT8N35e0MfuY3+7bLjFXS243ni4LBMEz6IAgKDsQBGUHgqDsQBCUHQiCsgNBUHYgiP8Ds1KRnXSdq28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a digit between 1 to 10,000\n",
    "image_index = 1234\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap = 'Greys')\n",
    "\n",
    "# make prediction\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "For this project, my model was able to recognise handwritten digits with 98.6% accuracy. I used the CNN algorithm because it is the best deep learning algorthim for images. I have also used Keras API built on top of TensorFlow because of it is one of the best machine learning algorthim right now. I have also used the best lost function and optimizer the industry has to offer when it comes to image recognition. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
